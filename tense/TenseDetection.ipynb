{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n",
    "#This script counts the following types of tense and compares to values in Bug_tt:\n",
    "#VBG = present_cont\n",
    "#VB and VBZ= present_simple\n",
    "#VBD and VBN = past tense\n",
    "#future: MD = 'will' 'shall'\n",
    "\n",
    "#the following script can be modified to read the processed_text column coming from our 542 data frame, and\n",
    "#then add these counts as 4 new columns to the df. These 4 columns are in replic_tense\n",
    "\n",
    "\n",
    "future = []\n",
    "past = []\n",
    "present_simple = []\n",
    "present_con = []\n",
    "\n",
    "bug_json = pd.read_json('Bug_tt.json')\n",
    "bug_tense = bug_json[['future','past','present_simple', 'present_con']]\n",
    "\n",
    "for i in np.arange(len(bug_json['comment'])):\n",
    "    pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "    tagged_words = list(pos_tagger.tag(bug_json['comment'][i].split()))\n",
    "\n",
    "    future_count = 0\n",
    "    past_count = 0\n",
    "    present_simple_count = 0\n",
    "    present_con_count = 0\n",
    "    for i in np.arange(len(tagged_words)):\n",
    "        if tagged_words[i][1] == 'MD' and (tagged_words[i][0] == 'will' or tagged_words[i][0] == 'shall'):\n",
    "            future_count+= 1\n",
    "        if (tagged_words[i][1] == 'VBD' or tagged_words[i][1] == 'VBN'):\n",
    "            past_count+= 1\n",
    "        if (tagged_words[i][1] == 'VBP' or tagged_words[i][1] == 'VBZ' or tagged_words[i][1] == 'VB'):\n",
    "            present_simple_count+= 1\n",
    "        if tagged_words[i][1] == 'VBG':\n",
    "            present_con_count+= 1\n",
    "            \n",
    "    future.append(future_count)\n",
    "    past.append(past_count)\n",
    "    present_simple.append(present_simple_count)\n",
    "    present_con.append(present_con_count)\n",
    "\n",
    "tense_dict = {'future': future, 'past': past, 'present_simple': present_simple, 'present_con': present_con}     \n",
    "replic_tense = pd.DataFrame(tense_dict)\n",
    "replic_tense = replic_tense[['future', 'past', 'present_simple','present_con']]\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(len(bug_tense['future'])):\n",
    "    if sum(replic_tense.iloc[i,:] == bug_tense.iloc[i,:]) == 4:\n",
    "        count+=1\n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future</th>\n",
       "      <th>past</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   future  past  present_simple  present_con\n",
       "0       0     0               2            1\n",
       "1       0     1               9            1\n",
       "2       0     0               3            1\n",
       "3       0     0               7            1\n",
       "4       0     5              18            2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replic_tense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future</th>\n",
       "      <th>past</th>\n",
       "      <th>present_simple</th>\n",
       "      <th>present_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   future  past  present_simple  present_con\n",
       "0       0     0               2            1\n",
       "1       0     1               9            0\n",
       "2       0     0               1            1\n",
       "3       0     1               4            1\n",
       "4       0     5              14            2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_tense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bug_tense = bug_json[['future','past','present_simple', 'present_con']]\n",
    "#bug_tense\n",
    "count = 0\n",
    "for i in np.arange(len(bug_tense['future'])):\n",
    "    if sum(replic_tense.iloc[i,:] == bug_tense.iloc[i,:]) == 4:\n",
    "        count+=1\n",
    "count\n",
    "#VBG = present_cont\n",
    "#VB, VBZ, VBP = present_simple\n",
    "#VBD and VBN = past tense\n",
    "#future: MD = 'will' 'shall', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('app', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('predictable,', 'NNP'),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('full', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('bugs', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('is', 'VBZ'),\n",
       " ('unpredictable.', 'JJ'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('check', 'VB'),\n",
       " ('in,', 'NNP'),\n",
       " ('take', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('screen', 'NN'),\n",
       " ('shot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('boarding', 'VBG'),\n",
       " ('pass', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('print', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('backup', 'JJ'),\n",
       " ('copy,', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('access', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('most.', 'FW')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "stanford_dir = \"/Users/cdonoff/Desktop/DataSci/data_553/project/ReviewClassifier4J/stanford-postagger-full-2018-10-16\"\n",
    "modelfile = stanford_dir+\"/models/english-bidirectional-distsim.tagger\"\n",
    "jarfile=stanford_dir+\"/stanford-postagger.jar\"\n",
    "tagger=StanfordPOSTagger(model_filename=modelfile, path_to_jar=jarfile)\n",
    "tagger.tag(\"This could be a great app if it was predictable, but it is full of bugs and is unpredictable.  if you are able to check in, take a screen shot of your boarding pass or print a backup copy, because you may not be able to access it when you need it most.\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('app', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('predictable', 'JJ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('full', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('bugs', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('is', 'VBZ'),\n",
       " ('unpredictable', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('check', 'VB'),\n",
       " ('in', 'IN'),\n",
       " (',', ','),\n",
       " ('take', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('screen', 'NN'),\n",
       " ('shot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('boarding', 'VBG'),\n",
       " ('pass', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('print', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('backup', 'NN'),\n",
       " ('copy', 'NN'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('access', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('most', 'RBS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "list(pos_tagger.tag(\"This could be a great app if it was predictable, but it is full of bugs and is unpredictable.  if you are able to check in, take a screen shot of your boarding pass or print a backup copy, because you may not be able to access it when you need it most.\".split()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json\n",
    "\n",
    "class StanfordNLP:\n",
    "    def __init__(self, host='http://localhost', port=9000):\n",
    "        self.nlp = StanfordCoreNLP(host, port=port,\n",
    "                                   timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n",
    "        self.props = {\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation',\n",
    "            'pipelineLanguage': 'en',\n",
    "            'outputFormat': 'json'\n",
    "        }\n",
    "\n",
    "    def word_tokenize(self, sentence):\n",
    "        return self.nlp.word_tokenize(sentence)\n",
    "\n",
    "    def pos(self, sentence):\n",
    "        return self.nlp.pos_tag(sentence)\n",
    "\n",
    "    def ner(self, sentence):\n",
    "        return self.nlp.ner(sentence)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        return self.nlp.parse(sentence)\n",
    "\n",
    "    def dependency_parse(self, sentence):\n",
    "        return self.nlp.dependency_parse(sentence)\n",
    "\n",
    "    def annotate(self, sentence):\n",
    "        return json.loads(self.nlp.annotate(sentence, properties=self.props))\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_to_dict(_tokens):\n",
    "        tokens = defaultdict(dict)\n",
    "        for token in _tokens:\n",
    "            tokens[int(token['index'])] = {\n",
    "                'word': token['word'],\n",
    "                'lemma': token['lemma'],\n",
    "                'pos': token['pos'],\n",
    "                'ner': token['ner']\n",
    "            }\n",
    "        return tokens\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sNLP = StanfordNLP()\n",
    "    text = \"I liked very much the upgrade to pdfs (divisions and search) However, they aren't displaying anymore. Fix it and it will be perfect. Best wishes\"\n",
    "    #print(\"Annotate:\", sNLP.annotate(text))\n",
    "    print(\"POS:\", sNLP.pos(text))\n",
    "    #print(\"Tokens:\", sNLP.word_tokenize(text))\n",
    "    #print(\"NER:\", sNLP.ner(text))\n",
    "    #print(\"Parse:\", sNLP.parse(text))\n",
    "    #print(\"Dep Parse:\", sNLP.dependency_parse(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
