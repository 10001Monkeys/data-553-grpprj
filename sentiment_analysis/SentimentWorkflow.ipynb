{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm actually an old v2 python pretending to be a young, hip v3 python\n"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"I'm actually an old v2 python pretending to be a young, hip v3 python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.24.2'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Check validity of Sentiment Analysis method \n",
    "### (using original dataset provided with paper)\n",
    "\n",
    "The first set of cells is working with the training+test set data provided in the paper. I am loading in the json files, cleaning the comment field to remove return characters ('\\n') and other things that cause problems when fed into the SentiTool. Then I am outputting a simple tab-delimited text file with the ID and comment field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug_tt.json processed\n",
      "Feature_tt.json processed\n",
      "Rating_tt.json processed\n",
      "UserExperience_tt.json processed\n"
     ]
    }
   ],
   "source": [
    "inpFiles = [\"Bug_tt.json\",\"Feature_tt.json\",\"Rating_tt.json\",\"UserExperience_tt.json\"]\n",
    "delimiter = \"\\t\".encode('utf-8')\n",
    "\n",
    "for entry in inpFiles:\n",
    "    tempDF = pd.read_json(entry)\n",
    "    tempDF[\"comment\"]=tempDF[\"comment\"].str.replace(\"\\n\",\" \",regex=False)\n",
    "    tempDF[\"comment\"]=tempDF[\"comment\"].str.replace(\"\\r\",\" \",regex=False)\n",
    "    tempDF[\"comment\"]=tempDF[\"comment\"].str.replace(\"\\t\",\" \",regex=False)\n",
    "    tempDF[\"comment\"]=tempDF[\"comment\"].str.rstrip() #white space at the end of a comment was creating a new line upon export\n",
    "    tempDF[\"comment\"]=tempDF[\"comment\"].str.lstrip() #no reason to keep leading whitespaces, so stripping off\n",
    "    tempDF[[\"id\",\"comment\"]].to_csv((entry.split(\".\")[0]+\"_for_senti.txt\"), header=True, index=False, sep=delimiter, encoding = \"utf-8\")\n",
    "    print(entry,\"processed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1  Next use the standalone SentiStrength application\n",
    "\n",
    "(This step must be performed manually outside of the notebook)\n",
    "\n",
    "Use SentiStrength 2.3 from (http://sentistrength.wlv.ac.uk/)\n",
    "Use Sept 21, 2011 configuration files downloaded from same site\n",
    "Use the following settings\n",
    "![settings0](sshot0-senti_settings0.png)\n",
    "![settings1](sshot1-senti_settings1.png)\n",
    "![settings1](sshot2-senti_settings2.png)\n",
    "![settings1](sshot3-senti_settings3.png)\n",
    "Use Sentiment Strength Analysis -> Analyze ALL Texts in File....As Above for ALL files in folder\n",
    "\n",
    "Yes to echo the header in the results\n",
    "\n",
    "Column 2 contains the text (do not use the default value of 3)\n",
    "\n",
    "results will be saved with \"+results\" appended to the filename in the folder where the input files were stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-2 Now read the results back in and compare\n",
    "\n",
    "The following reads both the original files and the results in as dataframes, merges them and compares the three categories of sentiment scores contained in the original _tt.json files with those that we just calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bug_tt\n",
      "SentiScore Matches: 594 / 722  =  0.8227146814404432\n",
      "PositiveSentiScore Matches: 650 / 722  =  0.9002770083102493\n",
      "NegativeSentiScore Matches: 606 / 722  =  0.8393351800554016\n",
      "Loading Feature_tt\n",
      "SentiScore Matches: 487 / 597  =  0.8157453936348409\n",
      "PositiveSentiScore Matches: 537 / 597  =  0.8994974874371859\n",
      "NegativeSentiScore Matches: 502 / 597  =  0.8408710217755444\n",
      "Loading Rating_tt\n",
      "SentiScore Matches: 605 / 721  =  0.8391123439667129\n",
      "PositiveSentiScore Matches: 658 / 721  =  0.912621359223301\n",
      "NegativeSentiScore Matches: 616 / 721  =  0.8543689320388349\n",
      "Loading UserExperience_tt\n",
      "SentiScore Matches: 608 / 728  =  0.8351648351648352\n",
      "PositiveSentiScore Matches: 650 / 728  =  0.8928571428571429\n",
      "NegativeSentiScore Matches: 636 / 728  =  0.8736263736263736\n"
     ]
    }
   ],
   "source": [
    "delimiter = \"\\t\".encode('utf-8')\n",
    "\n",
    "def find_max_sent(vect):\n",
    "    pos=vect[0]\n",
    "    neg=vect[1]\n",
    "    if abs(pos)>abs(neg):\n",
    "        return pos\n",
    "    else:\n",
    "        return neg\n",
    "#***In cases of ties, the authors appear to have chosen to use the negative sentiment score instead of a neutral 0!\n",
    "\n",
    "for entry in inpFiles:\n",
    "    print(\"Loading\", entry.split(\".\")[0])\n",
    "    origDF = pd.read_json(entry)\n",
    "    origDF[\"comment\"]=origDF[\"comment\"].str.replace(\"\\n\",\" \",regex=False)\n",
    "    origDF[\"comment\"]=origDF[\"comment\"].str.replace(\"\\r\",\" \",regex=False)\n",
    "    origDF[\"comment\"]=origDF[\"comment\"].str.replace(\"\\t\",\" \",regex=False)\n",
    "    origDF[\"comment\"]=origDF[\"comment\"].str.rstrip() #white space at the end of a comment was creating a new line upon export\n",
    "    origDF[\"comment\"]=origDF[\"comment\"].str.lstrip() #no reason to keep leading whitespaces, so stripping off\n",
    "    resultsDF = pd.read_csv(entry.split(\".\")[0]+\"_for_senti+results.txt\", sep=delimiter, encoding=\"utf-8\")\n",
    "    origDF = origDF.merge(resultsDF, on=[\"id\",\"comment\"])\n",
    "    origDF[\"Score\"] = origDF[[\"Positive\",\"Negative\"]].apply(find_max_sent, axis=1)\n",
    "    n = origDF[\"id\"].count()\n",
    "    totScoreMatch = sum(origDF[\"sentiScore\"]==origDF[\"Score\"])\n",
    "    negScoreMatch = sum(origDF[\"sentiScore_neg\"]==origDF[\"Negative\"])\n",
    "    posScoreMatch = sum(origDF[\"sentiScore_pos\"]==origDF[\"Positive\"])\n",
    "    \n",
    "    print(\"SentiScore Matches:\",totScoreMatch,\"/\",n,\" = \", totScoreMatch/n)\n",
    "    print(\"PositiveSentiScore Matches:\",posScoreMatch,\"/\",n,\" = \", posScoreMatch/n)\n",
    "    print(\"NegativeSentiScore Matches:\",negScoreMatch,\"/\",n,\" = \", negScoreMatch/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "# 1 Prepare sampled dataset for sentiment analysis\n",
    "\n",
    "### This step will likely be unnecessary in the combined workflow notebook as we will instead already have a dataframe in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_384_all_coded.csv_for_senti.txt saved for input to sentiStrength\n"
     ]
    }
   ],
   "source": [
    "filename = \"sample_384_all_coded.csv\"\n",
    "delimiter = \"\\t\".encode('utf-8')\n",
    "\n",
    "\n",
    "tempDF = pd.read_csv(filename, encoding=\"utf-8\")\n",
    "tempDF[\"processed_text\"]=tempDF[\"processed_text\"].str.replace(\"\\n\",\" \",regex=False)\n",
    "tempDF[\"processed_text\"]=tempDF[\"processed_text\"].str.replace(\"\\r\",\" \",regex=False)\n",
    "tempDF[\"processed_text\"]=tempDF[\"processed_text\"].str.replace(\"\\t\",\" \",regex=False)\n",
    "tempDF[\"processed_text\"]=tempDF[\"processed_text\"].str.rstrip() #white space at the end of a processed_text was creating a new line upon export\n",
    "tempDF[\"processed_text\"]=tempDF[\"processed_text\"].str.lstrip() #no reason to keep leading whitespaces, so stripping off\n",
    "tempDF[[\"id\",\"processed_text\"]].to_csv(filename+\"_for_senti.txt\", header=True, index=False, sep=delimiter, encoding = \"utf-8\")\n",
    "print(filename+\"_for_senti.txt saved for input to sentiStrength\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**See Step 0-1 for the correct configuration to use in the stand alone SentiStrength application**\n",
    "\n",
    "(replace this cell with that information if we are removing all of step 0 when merging this notebook to the combined workflow document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>appTitle</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>fileDate</th>\n",
       "      <th>fileCategories</th>\n",
       "      <th>contentRating</th>\n",
       "      <th>appId</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>label_UE</th>\n",
       "      <th>label_BR</th>\n",
       "      <th>label_FR</th>\n",
       "      <th>label_R</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>sentiScore_neg</th>\n",
       "      <th>sentiScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804084</td>\n",
       "      <td>PBS KIDS Video</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>15-Aug-17</td>\n",
       "      <td>5</td>\n",
       "      <td>It,s great gots lot of show it,s great 5  stars</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>org.pbskids.video</td>\n",
       "      <td>1333153</td>\n",
       "      <td>It's great, got lots of shows, 5 stars</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>869576</td>\n",
       "      <td>IRS2Go</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>23-Mar-15</td>\n",
       "      <td>5</td>\n",
       "      <td>Teacher Used the app to check on the status of...</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>gov.irs</td>\n",
       "      <td>1436222</td>\n",
       "      <td>Teacher Used the app to check on the status of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425433</td>\n",
       "      <td>Google Play Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-Mar-19</td>\n",
       "      <td>1</td>\n",
       "      <td>It was enjoyable and educative a good one.</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Teen</td>\n",
       "      <td>com.google.android.play.games</td>\n",
       "      <td>726513</td>\n",
       "      <td>It was enjoyable and educative a good one.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855228</td>\n",
       "      <td>Venmo Mobile Wallet: Send &amp; Receive Money</td>\n",
       "      <td>Linda Logan</td>\n",
       "      <td>05-Mar-19</td>\n",
       "      <td>5</td>\n",
       "      <td>great way to send or receive money</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>com.venmo</td>\n",
       "      <td>1414907</td>\n",
       "      <td>great way to send or receive money</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010397</td>\n",
       "      <td>Love Poly - New puzzle game</td>\n",
       "      <td>Valerie P</td>\n",
       "      <td>10-Mar-19</td>\n",
       "      <td>2</td>\n",
       "      <td>the amount of ads is ridiculous.</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>com.love.poly.puzzle.game</td>\n",
       "      <td>1653018</td>\n",
       "      <td>the amount of ads is ridiculous.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                   appTitle       userName  \\\n",
       "0   804084                             PBS KIDS Video  A Google User   \n",
       "1   869576                                     IRS2Go  A Google User   \n",
       "2   425433                          Google Play Games            NaN   \n",
       "3   855228  Venmo Mobile Wallet: Send & Receive Money    Linda Logan   \n",
       "4  1010397                Love Poly - New puzzle game      Valerie P   \n",
       "\n",
       "        date  score                                               text  \\\n",
       "0  15-Aug-17      5    It,s great gots lot of show it,s great 5  stars   \n",
       "1  23-Mar-15      5  Teacher Used the app to check on the status of...   \n",
       "2  19-Mar-19      1         It was enjoyable and educative a good one.   \n",
       "3  05-Mar-19      5                 great way to send or receive money   \n",
       "4  10-Mar-19      2                   the amount of ads is ridiculous.   \n",
       "\n",
       "     fileDate fileCategories contentRating                          appId  \\\n",
       "0  2019-04-14      EDUCATION      Everyone              org.pbskids.video   \n",
       "1  2019-03-24        FINANCE      Everyone                        gov.irs   \n",
       "2  2019-03-24  ENTERTAINMENT          Teen  com.google.android.play.games   \n",
       "3  2019-03-08        FINANCE      Everyone                      com.venmo   \n",
       "4  2019-04-01         FAMILY      Everyone      com.love.poly.puzzle.game   \n",
       "\n",
       "   reviewId                                     processed_text  label_UE  \\\n",
       "0   1333153             It's great, got lots of shows, 5 stars         0   \n",
       "1   1436222  Teacher Used the app to check on the status of...         1   \n",
       "2    726513         It was enjoyable and educative a good one.         0   \n",
       "3   1414907                 great way to send or receive money         0   \n",
       "4   1653018                   the amount of ads is ridiculous.         0   \n",
       "\n",
       "   label_BR  label_FR  label_R  sentiScore_pos  sentiScore_neg  sentiScore  \n",
       "0         0         0        1               3              -1           3  \n",
       "1         0         0        0               1              -1          -1  \n",
       "2         0         0        1               3              -1           3  \n",
       "3         0         0        1               3              -1           3  \n",
       "4         0         0        1               1              -3          -3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_sent(vect):\n",
    "    pos=vect[0]\n",
    "    neg=vect[1]\n",
    "    if abs(pos)>abs(neg):\n",
    "        return pos\n",
    "    else:\n",
    "        return neg #The authors of the paper appear to have used the negative score in the event of a tie\n",
    "\n",
    "resultsDF = pd.read_csv(filename+\"_for_senti+results.txt\", sep=delimiter, encoding=\"utf-8\")\n",
    "tempDF = tempDF.merge(resultsDF, on=[\"id\",\"processed_text\"]) #could do it just on ID. Don't really need to bring processed text back in either\n",
    "\n",
    "#assign a single sentiment score based on whichever value is further from neutral (0)\n",
    "tempDF[\"sentiScore\"] = tempDF[[\"Positive\",\"Negative\"]].apply(find_max_sent, axis=1)\n",
    "#rename the other two sentiment score columns to match what they are called in the paper's original dataset\n",
    "tempDF.rename(columns={\"Positive\":\"sentiScore_pos\",\"Negative\":\"sentiScore_neg\"}, inplace=True)\n",
    "\n",
    "tempDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiScore\n",
       "-4     22\n",
       "-3     20\n",
       "-2     45\n",
       "-1     79\n",
       " 2     71\n",
       " 3    121\n",
       " 4     14\n",
       "Name: appTitle, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick groupby analysis to see how many records exist for each sentiment score\n",
    "\n",
    "tempDF.groupby([\"sentiScore\"]).appTitle.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
